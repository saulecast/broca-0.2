{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import sqlite3\n",
    "import random\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "import numpy as np\n",
    "import re\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Definir el origen de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando diccionario...\n",
      "Diccionario creado\n"
     ]
    }
   ],
   "source": [
    "Base_de_datos = sqlite3.connect(\"Base de datos de Beige mejorada.db\", check_same_thread=False)\n",
    "cursor = Base_de_datos.cursor()\n",
    "bbdd = cursor.execute(\"SELECT entrada,salida FROM oración\")\n",
    "# with open(\"fragmento de el viejo y el mar.txt\") as f:\n",
    "#     bbdd = f.read()\n",
    "\n",
    "#Ahora crearemos un diccionario que definirá todas las conexiones entre las palabras en las respuestas vinculadas de cada una de las entradas\n",
    "diccionario = {}\n",
    "print(\"Creando diccionario...\")\n",
    "diccionario[\"__INICIO__\"] = [] #creo la entrada inicial del diccionario. Esta es la lista de palabras que pueden iniciar la oración\n",
    "try: #si lees desde una base de datos se ejecuta esta\n",
    "    for respuesta in bbdd:\n",
    "        palabras_en_oracion = respuesta[1] #si vas a activar el quitar signos de puntuacion(linea de abajo), sería bueno tambien ponerle .lower() a esto para que las palabras que iban despues de un punto ya no estén mayusculas\n",
    "        # palabras_en_oracion = re.sub(r'[^\\w\\s]', '', palabras_en_oracion) #esto de aquí quita los signos de puntuación... no me parece necesario\n",
    "        palabras_en_oracion = palabras_en_oracion.split()\n",
    "        for indice, palabra in enumerate(palabras_en_oracion):\n",
    "            if indice == 0:\n",
    "                diccionario[\"__INICIO__\"].append(palabra)\n",
    "\n",
    "            if indice < len(palabras_en_oracion) - 1 :\n",
    "                siguiente_palabra = palabras_en_oracion[indice+1]\n",
    "            else:\n",
    "                siguiente_palabra = \"__FIN__\"\n",
    "            \n",
    "            if palabra not in diccionario:\n",
    "                diccionario[palabra] = []\n",
    "                diccionario[palabra].append(siguiente_palabra)\n",
    "            elif palabra in diccionario:\n",
    "                diccionario[palabra].append(siguiente_palabra)\n",
    "except: #si lees desde un archivo de texto fallará la lectura dede base de datos, ejecutemos esta\n",
    "    palabras_en_oracion = bbdd\n",
    "    # palabras_en_oracion = re.sub(r'[^\\w\\s]', '', palabras_en_oracion) #esto de aquí quita los signos de puntuación... no me parece necesario\n",
    "    palabras_en_oracion = palabras_en_oracion.split()\n",
    "    for indice, palabra in enumerate(palabras_en_oracion):\n",
    "        if indice == 0:\n",
    "            diccionario[\"__INICIO__\"].append(palabra)\n",
    "\n",
    "        if indice < len(palabras_en_oracion) - 1:\n",
    "            siguiente_palabra = palabras_en_oracion[indice+1]\n",
    "        else:\n",
    "            siguiente_palabra = \"__FIN__\"\n",
    "\n",
    "        if palabra not in diccionario:\n",
    "            diccionario[palabra] = []\n",
    "            diccionario[palabra].append(siguiente_palabra)\n",
    "        elif palabra in diccionario:\n",
    "            diccionario[palabra].append(siguiente_palabra)\n",
    "print(\"Diccionario creado\")\n",
    "# print(diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Preparación de datos en forma numerica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Preparación y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empezando\n",
      "terminado\n"
     ]
    }
   ],
   "source": [
    "#obtención y preparación de datos\n",
    "letras_a_numeros = {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5, \"f\": 6, \"g\": 7, \"h\": 8, \"i\": 9, \"j\": 10,\n",
    "               \"k\": 11, \"l\": 12, \"m\": 13, \"n\": 14, \"ñ\": 15, \"o\": 16, \"p\": 17, \"q\": 18, \"r\": 19, \"s\": 20, \"t\": 21, \"u\": 22, \"v\": 23, \"w\": 24, \"x\": 25, \"y\": 26, \"z\": 27}\n",
    "bbdd = cursor.execute(\"SELECT entrada,salida FROM oración\")\n",
    "print(\"empezando\")\n",
    "lista_entrada = []\n",
    "lista_salida = []\n",
    "\n",
    "mas_larga = 0 \n",
    "for fila in bbdd:\n",
    "    entrada = fila[0].lower()\n",
    "    entrada = re.sub(r'[^\\w\\s]', '', entrada)  # quito signos de puntuacion\n",
    "    #quitamos tildes\n",
    "    entrada = re.sub(\n",
    "        r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\",\n",
    "        normalize(\"NFD\", entrada), 0, re.I\n",
    "    ) \n",
    "    entrada = normalize('NFC', entrada) #normalizo\n",
    "    oracion = []\n",
    "    for palabra in entrada.lower():\n",
    "        if \"ñ\" in palabra:\n",
    "            oracion.append(28.0)\n",
    "        elif \" \" in palabra:\n",
    "            oracion.append(0.0)\n",
    "        else:\n",
    "            try:\n",
    "                oracion.append(float(string.ascii_lowercase.index(palabra)+1))\n",
    "            except ValueError:\n",
    "                oracion.append(float(palabra))\n",
    "    if len(oracion) > mas_larga:\n",
    "        mas_larga = len(oracion)\n",
    "    lista_entrada.append(np.array(oracion, dtype = float))\n",
    "\n",
    "\n",
    "    #respuestas de salida\n",
    "    salida = fila[1].lower()\n",
    "    # print(salida)\n",
    "    salida = re.sub(r'[^\\w\\s]', '', salida)  # quito signos de puntuacion\n",
    "    #quitamos tildes\n",
    "    salida = re.sub(\n",
    "        r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\",\n",
    "        normalize(\"NFD\", salida), 0, re.I\n",
    "    ) \n",
    "    salida = normalize('NFC', salida) #normalizo\n",
    "    oracion = []\n",
    "    for palabra in salida.lower():\n",
    "        if \"ñ\" in palabra:\n",
    "            oracion.append(28.0)\n",
    "        elif \" \" in palabra:\n",
    "            oracion.append(0.0)\n",
    "        else:\n",
    "            try:\n",
    "                oracion.append(float(string.ascii_lowercase.index(palabra)+1))\n",
    "            except ValueError:\n",
    "                oracion.append(float(palabra))\n",
    "    if len(oracion) > mas_larga:\n",
    "        mas_larga = len(oracion)\n",
    "    lista_salida.append(np.array(oracion, dtype = float))\n",
    "\n",
    "# print(lista_entrada)\n",
    "# print(lista_salida)\n",
    "# print(mas_larga)\n",
    "print(\"terminado\")\n",
    "\n",
    "#ajustamos todos los arreglos que corresponden a oraciones para tener la misma longitud\n",
    "for indice, arreglo in enumerate(lista_entrada):\n",
    "    diferencia = mas_larga - len(arreglo)\n",
    "    lista_entrada[indice] = np.append(arreglo, np.zeros(diferencia, dtype = float))\n",
    "\n",
    "for indice, arreglo in enumerate(lista_salida):\n",
    "    diferencia = mas_larga - len(arreglo)\n",
    "    lista_salida[indice] = np.append(arreglo, np.zeros(diferencia, dtype = float))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opciones de entrenamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Original hecho por mí, sin casi experiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando...\n",
      "Entrenado\n",
      "Respuestas:\n",
      "21/21 [==============================] - 0s 1ms/step\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "#Creamos las capas de la red neuronal y establecemos su secuencia\n",
    "capa_oculta1 = tf.keras.layers.Dense(units = 100, input_dim = mas_larga )\n",
    "capa_oculta2 = tf.keras.layers.Dense(units = 150)\n",
    "capa_oculta3 = tf.keras.layers.Dense(units = 200)\n",
    "capa_oculta4 = tf.keras.layers.Dense(units = 70)\n",
    "capa_oculta5 = tf.keras.layers.Dense(units = 50)\n",
    "capa_oculta6 = tf.keras.layers.Dense(units = 10)\n",
    "# capa_oculta6 = tf.keras.layers.Dense(units = 1000)\n",
    "capa_salida = tf.keras.layers.Dense(units=mas_larga)\n",
    "# capa_oculta2, capa_salida])\n",
    "modelo = tf.keras.Sequential([capa_oculta1, capa_oculta2, capa_oculta3, capa_oculta4, capa_oculta5, capa_oculta6, capa_salida])\n",
    "\n",
    "#compilo en modelo\n",
    "modelo.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(0.1),\n",
    "    loss = \"mean_squared_error\",\n",
    ")\n",
    "\n",
    "\n",
    "# #entrenamiento del modelo\n",
    "lista_entrada = np.array(lista_entrada) #keras solo trabaja con arreglos numpy\n",
    "lista_salida = np.array(lista_salida) #keras solo trabaja con arreglos numpy\n",
    "\n",
    "print(\"\\nEntrenando...\")\n",
    "historia = modelo.fit(lista_entrada, lista_salida, epochs=1000, verbose=False)\n",
    "print(\"Entrenado\\nRespuestas:\")\n",
    "\n",
    "# predecir = np.array([100.0,200.0,300.0,400.0,500.0,600.0,700.0,800.0])\n",
    "# diferencia = mas_larga - len(predecir)\n",
    "# predecir = np.append(predecir, np.zeros(diferencia, dtype=float))\n",
    "\n",
    "print( modelo.predict(lista_entrada) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. hecho por chat gpt en base a mi diseño anterior y luego modificado por mí y chatgpt otra vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 2s - loss: 4231.8960 - accuracy: 0.0133 - val_loss: 3750.0708 - val_accuracy: 0.0152 - 2s/epoch - 128ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 5090.6318 - accuracy: 0.0303 - val_loss: 1801.0952 - val_accuracy: 0.0152 - 107ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 4974.6284 - accuracy: 0.0379 - val_loss: 3649.9827 - val_accuracy: 0.0152 - 176ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 5033.0474 - accuracy: 0.0303 - val_loss: 3582.1516 - val_accuracy: 0.0152 - 210ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 4970.3359 - accuracy: 0.0265 - val_loss: 3482.5481 - val_accuracy: 0.0152 - 196ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 4796.4238 - accuracy: 0.0246 - val_loss: 3433.5032 - val_accuracy: 0.0152 - 197ms/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 4555.2832 - accuracy: 0.0265 - val_loss: 2137.0920 - val_accuracy: 0.0152 - 190ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 3960.6638 - accuracy: 0.0322 - val_loss: 2404.7637 - val_accuracy: 0.0152 - 213ms/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 3867.0825 - accuracy: 0.0814 - val_loss: 2306.4631 - val_accuracy: 0.1212 - 202ms/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 3893.8049 - accuracy: 0.0871 - val_loss: 1616.2606 - val_accuracy: 0.0530 - 191ms/epoch - 11ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 4103.0410 - accuracy: 0.0606 - val_loss: 2043.7126 - val_accuracy: 0.1212 - 193ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 4346.6523 - accuracy: 0.0852 - val_loss: 1843.8121 - val_accuracy: 0.1212 - 195ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 4598.0117 - accuracy: 0.0587 - val_loss: 3352.5044 - val_accuracy: 0.1212 - 188ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 4776.6113 - accuracy: 0.0814 - val_loss: 3246.3083 - val_accuracy: 0.1212 - 166ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 4249.8994 - accuracy: 0.0852 - val_loss: 3411.6387 - val_accuracy: 0.1212 - 185ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 4888.9883 - accuracy: 0.1023 - val_loss: 3415.4482 - val_accuracy: 0.1212 - 189ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 4709.4331 - accuracy: 0.0322 - val_loss: 3358.7847 - val_accuracy: 0.0455 - 150ms/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 4403.0649 - accuracy: 0.0417 - val_loss: 2051.7852 - val_accuracy: 0.0455 - 122ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 4180.8877 - accuracy: 0.0379 - val_loss: 2351.6992 - val_accuracy: 0.0455 - 180ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 4102.6294 - accuracy: 0.0833 - val_loss: 3224.1487 - val_accuracy: 0.1212 - 190ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 4600.6855 - accuracy: 0.0890 - val_loss: 3376.8379 - val_accuracy: 0.1212 - 193ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 4588.8330 - accuracy: 0.0909 - val_loss: 3309.5190 - val_accuracy: 0.1212 - 175ms/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 4244.9067 - accuracy: 0.0871 - val_loss: 3317.6289 - val_accuracy: 0.1212 - 173ms/epoch - 10ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 4606.9150 - accuracy: 0.0928 - val_loss: 3264.1882 - val_accuracy: 0.1212 - 192ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 4083.4502 - accuracy: 0.0871 - val_loss: 1761.6826 - val_accuracy: 0.1212 - 194ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 4102.2173 - accuracy: 0.0833 - val_loss: 1822.2107 - val_accuracy: 0.1212 - 190ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 4285.4326 - accuracy: 0.0852 - val_loss: 3267.7449 - val_accuracy: 0.1212 - 192ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 4049.3342 - accuracy: 0.0985 - val_loss: 3219.2026 - val_accuracy: 0.1212 - 200ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 4303.2622 - accuracy: 0.0928 - val_loss: 3160.2480 - val_accuracy: 0.1212 - 204ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 3547.2744 - accuracy: 0.0909 - val_loss: 1938.0615 - val_accuracy: 0.1212 - 181ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 3946.5425 - accuracy: 0.0909 - val_loss: 3031.7019 - val_accuracy: 0.1212 - 165ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 3849.0430 - accuracy: 0.0947 - val_loss: 3252.2463 - val_accuracy: 0.1212 - 210ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 4142.3281 - accuracy: 0.0909 - val_loss: 1612.3097 - val_accuracy: 0.1212 - 181ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 3902.0781 - accuracy: 0.0947 - val_loss: 1572.7101 - val_accuracy: 0.1212 - 217ms/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 4470.7363 - accuracy: 0.0985 - val_loss: 3228.0259 - val_accuracy: 0.1212 - 165ms/epoch - 10ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 3833.2595 - accuracy: 0.0928 - val_loss: 3100.1189 - val_accuracy: 0.1212 - 154ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 3730.0154 - accuracy: 0.0833 - val_loss: 1727.9652 - val_accuracy: 0.1212 - 162ms/epoch - 10ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 3848.0134 - accuracy: 0.0795 - val_loss: 3105.6287 - val_accuracy: 0.1212 - 151ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 3780.1443 - accuracy: 0.0890 - val_loss: 1575.9669 - val_accuracy: 0.1212 - 215ms/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 3961.4019 - accuracy: 0.1004 - val_loss: 3209.1206 - val_accuracy: 0.1212 - 168ms/epoch - 10ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 3789.7437 - accuracy: 0.1023 - val_loss: 1872.0739 - val_accuracy: 0.1212 - 156ms/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 3733.2805 - accuracy: 0.0909 - val_loss: 2183.1729 - val_accuracy: 0.1212 - 189ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 3734.8230 - accuracy: 0.0682 - val_loss: 1993.4858 - val_accuracy: 0.1212 - 160ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 4317.4375 - accuracy: 0.0890 - val_loss: 3307.2993 - val_accuracy: 0.1212 - 177ms/epoch - 10ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 4469.1826 - accuracy: 0.0890 - val_loss: 3265.6270 - val_accuracy: 0.1212 - 222ms/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 4029.2666 - accuracy: 0.0909 - val_loss: 3163.7603 - val_accuracy: 0.1212 - 155ms/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 3840.1538 - accuracy: 0.0852 - val_loss: 1581.0547 - val_accuracy: 0.1212 - 178ms/epoch - 10ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 3607.5234 - accuracy: 0.0947 - val_loss: 3201.8022 - val_accuracy: 0.1212 - 186ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 4071.7212 - accuracy: 0.0833 - val_loss: 1582.3596 - val_accuracy: 0.1212 - 166ms/epoch - 10ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 3835.3730 - accuracy: 0.0928 - val_loss: 3085.7830 - val_accuracy: 0.1212 - 177ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 3968.6978 - accuracy: 0.0833 - val_loss: 1597.3632 - val_accuracy: 0.1212 - 138ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 3741.1079 - accuracy: 0.0871 - val_loss: 3120.2900 - val_accuracy: 0.1212 - 161ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 4035.5815 - accuracy: 0.0852 - val_loss: 1572.0979 - val_accuracy: 0.1212 - 153ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 3639.4492 - accuracy: 0.0852 - val_loss: 3073.9404 - val_accuracy: 0.1212 - 148ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 3623.6440 - accuracy: 0.0852 - val_loss: 3098.9180 - val_accuracy: 0.1212 - 138ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 3805.1699 - accuracy: 0.0890 - val_loss: 1599.9103 - val_accuracy: 0.1212 - 145ms/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 3708.5005 - accuracy: 0.0909 - val_loss: 1801.5947 - val_accuracy: 0.1212 - 151ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 3667.5684 - accuracy: 0.0871 - val_loss: 3154.3606 - val_accuracy: 0.1212 - 126ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 4412.3481 - accuracy: 0.0966 - val_loss: 1571.2897 - val_accuracy: 0.1212 - 142ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 3472.7930 - accuracy: 0.0833 - val_loss: 3082.4749 - val_accuracy: 0.1212 - 150ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 3855.6250 - accuracy: 0.0966 - val_loss: 3095.7268 - val_accuracy: 0.1212 - 140ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 3615.2485 - accuracy: 0.0947 - val_loss: 1571.2411 - val_accuracy: 0.1212 - 127ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 3842.9021 - accuracy: 0.0966 - val_loss: 3132.6394 - val_accuracy: 0.1212 - 139ms/epoch - 8ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 3560.4348 - accuracy: 0.0814 - val_loss: 1572.6200 - val_accuracy: 0.1212 - 161ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 3740.3047 - accuracy: 0.0928 - val_loss: 1650.9097 - val_accuracy: 0.1212 - 126ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 3747.7422 - accuracy: 0.0871 - val_loss: 1570.9657 - val_accuracy: 0.1212 - 128ms/epoch - 8ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 3760.1685 - accuracy: 0.0928 - val_loss: 3154.2725 - val_accuracy: 0.1212 - 149ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 4022.4465 - accuracy: 0.0966 - val_loss: 3030.1785 - val_accuracy: 0.1212 - 124ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 3776.9868 - accuracy: 0.0852 - val_loss: 1661.8704 - val_accuracy: 0.1212 - 155ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 3674.3801 - accuracy: 0.0833 - val_loss: 3126.0046 - val_accuracy: 0.1212 - 163ms/epoch - 10ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 3794.1445 - accuracy: 0.0833 - val_loss: 3055.4387 - val_accuracy: 0.1212 - 154ms/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 3634.4231 - accuracy: 0.0871 - val_loss: 3008.4124 - val_accuracy: 0.1212 - 159ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 3608.8420 - accuracy: 0.0720 - val_loss: 1622.3651 - val_accuracy: 0.1212 - 152ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 3673.1189 - accuracy: 0.0833 - val_loss: 1570.6608 - val_accuracy: 0.1212 - 122ms/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 3808.6765 - accuracy: 0.0890 - val_loss: 1570.9087 - val_accuracy: 0.1212 - 136ms/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 3599.0144 - accuracy: 0.0985 - val_loss: 1570.6034 - val_accuracy: 0.1212 - 138ms/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 3446.8184 - accuracy: 0.0739 - val_loss: 1570.6958 - val_accuracy: 0.1212 - 138ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 4016.7983 - accuracy: 0.0947 - val_loss: 1579.6000 - val_accuracy: 0.1212 - 144ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 3942.4551 - accuracy: 0.0720 - val_loss: 3144.2283 - val_accuracy: 0.1212 - 140ms/epoch - 8ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 3776.0823 - accuracy: 0.0852 - val_loss: 3029.8486 - val_accuracy: 0.1212 - 140ms/epoch - 8ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 3305.7771 - accuracy: 0.0833 - val_loss: 3029.7305 - val_accuracy: 0.1212 - 121ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 3718.2319 - accuracy: 0.0701 - val_loss: 1585.9536 - val_accuracy: 0.1212 - 107ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 3644.3672 - accuracy: 0.0682 - val_loss: 3176.8264 - val_accuracy: 0.1212 - 109ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 3833.5422 - accuracy: 0.0833 - val_loss: 3139.6863 - val_accuracy: 0.1212 - 116ms/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 3786.0452 - accuracy: 0.0890 - val_loss: 1826.6719 - val_accuracy: 0.1212 - 114ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 3670.1362 - accuracy: 0.0833 - val_loss: 1575.5865 - val_accuracy: 0.1212 - 109ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 3529.7788 - accuracy: 0.0795 - val_loss: 1657.9623 - val_accuracy: 0.1212 - 122ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 3718.7314 - accuracy: 0.0833 - val_loss: 3058.8745 - val_accuracy: 0.1212 - 121ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 3637.8401 - accuracy: 0.0663 - val_loss: 3030.0679 - val_accuracy: 0.1212 - 120ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 3581.1633 - accuracy: 0.0909 - val_loss: 1657.5662 - val_accuracy: 0.1212 - 122ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 3493.2825 - accuracy: 0.0777 - val_loss: 3029.3962 - val_accuracy: 0.1212 - 99ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 3394.4214 - accuracy: 0.0758 - val_loss: 1641.9229 - val_accuracy: 0.1212 - 107ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 3681.3757 - accuracy: 0.0758 - val_loss: 3149.7869 - val_accuracy: 0.1212 - 123ms/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 3743.2612 - accuracy: 0.0795 - val_loss: 3055.0430 - val_accuracy: 0.1212 - 135ms/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 3736.7617 - accuracy: 0.0852 - val_loss: 3119.8469 - val_accuracy: 0.1212 - 115ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 3698.9124 - accuracy: 0.0985 - val_loss: 3233.8196 - val_accuracy: 0.1212 - 108ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "17/17 - 0s - loss: 4511.2817 - accuracy: 0.0928 - val_loss: 1609.3383 - val_accuracy: 0.1212 - 101ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 3352.4817 - accuracy: 0.0890 - val_loss: 1569.9335 - val_accuracy: 0.1212 - 117ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 3713.4529 - accuracy: 0.0890 - val_loss: 1642.6459 - val_accuracy: 0.1212 - 105ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "17/17 - 0s - loss: 3577.9944 - accuracy: 0.0720 - val_loss: 1570.4926 - val_accuracy: 0.1212 - 99ms/epoch - 6ms/step\n",
      "21/21 [==============================] - 0s 2ms/step\n",
      "[[-45414.652    38470.605   -30912.242   ...   4028.2974     975.02234\n",
      "   -1952.0726 ]\n",
      " [-28068.982    23777.467   -19106.566   ...   2489.6924     602.5436\n",
      "   -1206.4187 ]\n",
      " [-23038.572    19516.338   -15682.118   ...   2043.5402     494.61005\n",
      "    -990.1661 ]\n",
      " ...\n",
      " [-12554.824    10635.81     -8545.918   ...   1113.6758     269.59134\n",
      "    -539.48474]\n",
      " [-19710.434    16697.143   -13417.014   ...   1748.3206     423.13354\n",
      "    -847.097  ]\n",
      " [-15981.782    13538.703   -10878.594   ...   1417.6349     343.14957\n",
      "    -686.80457]]\n",
      "21/21 [==============================] - 0s 1ms/step\n",
      "[[-45414.652    38470.605   -30912.242   ...   4028.2974     975.02234\n",
      "   -1952.0726 ]\n",
      " [-28068.982    23777.467   -19106.566   ...   2489.6924     602.5436\n",
      "   -1206.4187 ]\n",
      " [-23038.572    19516.338   -15682.118   ...   2043.5402     494.61005\n",
      "    -990.1661 ]\n",
      " ...\n",
      " [-12554.824    10635.81     -8545.918   ...   1113.6758     269.59134\n",
      "    -539.48474]\n",
      " [-19710.434    16697.143   -13417.014   ...   1748.3206     423.13354\n",
      "    -847.097  ]\n",
      " [-15981.782    13538.703   -10878.594   ...   1417.6349     343.14957\n",
      "    -686.80457]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Configuración del modelo\n",
    "capas_ocultas = [100, 150, 200, 70, 50, 10]\n",
    "\n",
    "# Crear capas ocultas con dropout\n",
    "capas = [tf.keras.layers.Dense(units=capas_ocultas[0], input_dim=mas_larga, activation='relu')]\n",
    "for i in range(1, len(capas_ocultas)):\n",
    "    capa = tf.keras.layers.Dense(units=capas_ocultas[i], activation='relu')\n",
    "    capas.append(capa)\n",
    "    capas.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Crear modelo secuencial y agregar capas\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=capas_ocultas[0], input_dim=mas_larga, activation='relu', \n",
    "                          kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.2)\n",
    "])\n",
    "\n",
    "for i in range(1, len(capas_ocultas)):\n",
    "    capa = tf.keras.layers.Dense(units=capas_ocultas[i], activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.01))\n",
    "    modelo.add(capa)\n",
    "    modelo.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "modelo.add(tf.keras.layers.Dense(units=mas_larga))\n",
    "\n",
    "modelo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "               loss=\"categorical_crossentropy\",\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "historia = modelo.fit(lista_entrada, lista_salida, epochs=100, verbose=2, validation_split=0.2)\n",
    "\n",
    "print(modelo.predict(lista_entrada))\n",
    "\n",
    "\n",
    "# Predicción\n",
    "print(modelo.predict(lista_entrada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Ejecuciones de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dijiste: hola, saludos, buenos días\n",
      "mi respuesta es:  Se domestíca\n",
      "\n",
      "\n",
      "dijiste: hola\n",
      "mi respuesta es:  Sí! Muchas gracias, sí\n",
      "\n",
      "\n",
      "dijiste: hola\n",
      "mi respuesta es:  Dale, enséñame\n",
      "\n",
      "\n",
      "dijiste: hola\n",
      "mi respuesta es:  Me tienes, es un poco la creo, algo de notificaciones\n",
      "\n",
      "\n",
      "dijiste: hola\n",
      "mi respuesta es:  Pues aquí hay algo enredada ... Lo sé. Yo voy a mí eso es malo, diosito te duele reírte?\n",
      "\n",
      "\n",
      "dijiste: hola\n",
      "mi respuesta es:  Hombre con una cosa ni una palabra de niveles y las personas están durmiendo?\n",
      "\n",
      "\n",
      "dijiste: hola\n",
      "mi respuesta es:  Las nuevas metas y profundo\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  X2\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  Qué nos lo mejor\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  Ah sí?\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  Me tienes, es el amor de mí eso a escucharlo, detenidamente, notarás que necesitaba para qué es la escribió una respuesta\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  Lo sé... Era por la tengas me tienes razón .-.\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  I feel ashamed\n",
      "\n",
      "\n",
      "dijiste: adios\n",
      "mi respuesta es:  Para eso en pocisiones equivocadas y que hago lo menos que lo necesario para hacerlo, luego (me tardo mucho\n",
      "\n",
      "\n",
      "dijiste: hablas mañana\n",
      "mi respuesta es:  Las nuevas tareas difíciles\n",
      "\n",
      "\n",
      "dijiste: hablamos mañana\n",
      "mi respuesta es:  Jajajaja sí jode\n",
      "\n",
      "\n",
      "dijiste: hablamos mañana\n",
      "mi respuesta es:  Requete oscuro mi anterior profesor de verdad\n",
      "\n",
      "\n",
      "dijiste: jajajajajaja\n",
      "mi respuesta es:  Eso es... Siempre veo que no dejes de euforia)\n",
      "\n",
      "\n",
      "dijiste: jajaja\n",
      "mi respuesta es:  Ey! Te espero\n",
      "\n",
      "\n",
      "dijiste: jajajaja\n",
      "mi respuesta es:  Mard...? No sé, tú no... Entonces ya he estado haciendo\n",
      "\n",
      "\n",
      "dijiste: fin\n",
      "mi respuesta es:  Por ahora no es que encontré\n"
     ]
    }
   ],
   "source": [
    "entrada = \"\"\n",
    "while entrada != \"fin\":\n",
    "    print(\"\\n\")\n",
    "    entrada = input(\"Hablame: \")\n",
    "    palabra_obtenida = \"__INICIO__\"\n",
    "    limite = 280\n",
    "    oracion = \"\"\n",
    "    while len(oracion) < limite:\n",
    "        numero = random.randint(0, len(diccionario[palabra_obtenida])-1)\n",
    "        palabra_obtenida = diccionario[palabra_obtenida][numero]\n",
    "        if palabra_obtenida == \"__FIN__\":  \n",
    "            break\n",
    "        oracion += \" \" + palabra_obtenida\n",
    "    \n",
    "    print(\"dijiste: {0}\".format(entrada))\n",
    "    print(\"mi respuesta es: {0}\".format(oracion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TensorFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f9b6dadf8d2594b70c00562f7b417b535471bb52c31a31fdb1b929152f096e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
